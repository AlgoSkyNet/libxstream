<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>LIBXSTREAM by hfp</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">LIBXSTREAM</h1>
        <p class="header">Library to program with streams, events, and to queue own functions into a stream.</p>

        <ul>
          <li class="download"><a class="buttons" href="https://github.com/hfp/libxstream/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/hfp/libxstream/tarball/master">Download TAR</a></li>
          <li><a class="buttons github" href="https://github.com/hfp/libxstream">View On GitHub</a></li>
        </ul>

        <p class="header">This project is maintained by <a class="header name" href="https://github.com/hfp">hfp</a></p>


      </header>
      <section>
        <h1>
<a id="libxstream" class="anchor" href="#libxstream" aria-hidden="true"><span class="octicon octicon-link"></span></a>LIBXSTREAM</h1>

<p>LIBXSTREAM is a library to work with streams, events, and code regions that are able to run asynchronous while preserving the usual stream conditions. The library is targeting Intel Architecture (x86) and helps to offload work to an Intel Xeon Phi coprocessor (an instance of the Intel Many Integrated Core "MIC" Architecture). For example, using two streams may be an alternative to the usual double-buffering approach which can be used to hide buffer transfer time behind compute. [<a href="https://github.com/hfp/libxstream/raw/master/documentation/libxstream.pdf">pdf</a>] [<a href="https://github.com/hfp/libxstream/archive/0.9.0.zip">src</a>] <a href="https://github.com/hfp/libxstream/archive/master.zip"><img src="https://travis-ci.org/hfp/libxstream.svg?branch=master" alt="status" title="Master branch build status"></a></p>

<h2>
<a id="interface" class="anchor" href="#interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Interface</h2>

<p>The library's application programming interface (API) completely seals the implementation and only forward-declares types which are beyond the language's built-in types. The entire API consists of below subcategories each illustrated by a small code snippet. The <a href="#function-interface">Function Interface</a> for instance enables an own function to be enqueued for execution within a stream (via function pointer). A future release of the library will provide a native FORTRAN interface. [<a href="https://github.com/hfp/libxstream/blob/master/include/libxstream.h">c</a>]</p>

<h3>
<a id="data-types" class="anchor" href="#data-types" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Types</h3>

<p>Data types are forward-declared types used in the interface. Moreover, there is a mapping from the language's built-in types to the types supported in the <a href="#function-interface">Function Interface</a>.</p>

<div class="highlight highlight-source-c"><pre><span class="pl-c">/** Boolean state. */</span>
<span class="pl-k">typedef</span> <span class="pl-k">int</span> libxstream_bool;
<span class="pl-c">/** Stream type. */</span>
<span class="pl-k">typedef</span> <span class="pl-k">struct</span> libxstream_stream libxstream_stream;
<span class="pl-c">/** Event type. */</span>
<span class="pl-k">typedef</span> <span class="pl-k">struct</span> libxstream_event libxstream_event;
<span class="pl-c">/** Enumeration of elemental "scalar" types. */</span>
<span class="pl-k">typedef</span> <span class="pl-k">enum</span> libxstream_type { <span class="pl-c">/** see libxstream.h */</span>
  <span class="pl-c">/** special types: BOOL, BYTE, CHAR, VOID */</span>
  <span class="pl-c">/** signed integer types: I8, I16, I32, I64 */</span>
  <span class="pl-c">/** unsigned integer types: U8, U16, U32, U64 */</span>
  <span class="pl-c">/** floating point types: F32, F64, C32, C64 */</span>
} libxstream_type;
<span class="pl-c">/** Function call behavior (flags valid for binary combination). */</span>
<span class="pl-k">typedef</span> <span class="pl-k">enum</span> libxstream_call_flags {
  LIBXSTREAM_CALL_WAIT    = <span class="pl-c1">1</span> <span class="pl-c">/* synchronous function call */</span>,
  LIBXSTREAM_CALL_NATIVE  = <span class="pl-c1">2</span> <span class="pl-c">/* native host/MIC function */</span>,
  <span class="pl-c">/** collection of any valid flags from above */</span>
  LIBXSTREAM_CALL_DEFAULT = <span class="pl-c1">0</span>
} libxstream_call_flags;
<span class="pl-c">/** Function argument type. */</span>
<span class="pl-k">typedef</span> <span class="pl-k">struct</span> libxstream_argument libxstream_argument;
<span class="pl-c">/** Function type of an offloadable function. */</span>
<span class="pl-k">typedef</span> <span class="pl-en">void</span> (*libxstream_function)(LIBXSTREAM_VARIADIC);</pre></div>

<h3>
<a id="device-interface" class="anchor" href="#device-interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Device Interface</h3>

<p>The device interface allows to query the number of available devices as well as querying some important metrics (physical and available memory).</p>

<div class="highlight highlight-source-c"><pre><span class="pl-c1">size_t</span> ndevices = <span class="pl-c1">0</span>, allocatable = <span class="pl-c1">0</span>;
<span class="pl-en">libxstream_get_ndevices</span>(&amp;ndevices);
<span class="pl-en">libxstream_get_meminfo</span>(-<span class="pl-c1">1</span><span class="pl-c">/*host*/</span>, &amp;allocatable, <span class="pl-c1">NULL</span>);</pre></div>

<p>Beside of the minimalistic device-orientied functionality, this interface also allows to rely on the notion of an "active device". This way, multiple devices can be driven on a per host-thread basis.</p>

<div class="highlight highlight-source-c"><pre><span class="pl-c">/* Initialize active device on a per host-thread basis */</span>
<span class="pl-en">libxstream_set_active_device</span>(omp_get_thread_num() % ndevices);</pre></div>

<p>Relying on an active device is explicit for the entire library, and it is up to the user to make use of this notion.</p>

<div class="highlight highlight-source-c"><pre><span class="pl-k">int</span> device = -<span class="pl-c1">1</span>;
<span class="pl-en">libxstream_get_active_device</span>(&amp;device);
<span class="pl-en">libxstream_get_meminfo</span>(device, &amp;allocatable, <span class="pl-c1">NULL</span>);</pre></div>

<h3>
<a id="memory-interface" class="anchor" href="#memory-interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Memory Interface</h3>

<p>The memory interface is mainly for handling device-side buffers (allocation, copy). It is usually beneficial to allocate host memory using these functions as well. However, any memory allocation on the host is interoperable. It is also supported copying parts to/from a buffer.</p>

<div class="highlight highlight-source-c"><pre><span class="pl-k">const</span> <span class="pl-k">int</span> hst = -<span class="pl-c1">1</span>, dev = <span class="pl-c1">0</span>, i = <span class="pl-c1">0</span>;
<span class="pl-en">libxstream_mem_allocate</span>(hst, &amp;ihst, <span class="pl-k">sizeof</span>(<span class="pl-k">double</span>) * nitems, 0<span class="pl-c">/*auto-alignment*/</span>);
<span class="pl-en">libxstream_mem_allocate</span>(hst, &amp;ohst, <span class="pl-k">sizeof</span>(<span class="pl-k">double</span>) * nitems, 0<span class="pl-c">/*auto-alignment*/</span>);
<span class="pl-c">/* TODO: initialize with some input data */</span>
<span class="pl-en">libxstream_mem_allocate</span>(dev, &amp;idev, <span class="pl-k">sizeof</span>(<span class="pl-k">double</span>) * nbatch, 0<span class="pl-c">/*auto-alignment*/</span>);
<span class="pl-en">libxstream_mem_allocate</span>(dev, &amp;odev, <span class="pl-k">sizeof</span>(<span class="pl-k">double</span>) * nbatch, 0<span class="pl-c">/*auto-alignment*/</span>);

<span class="pl-k">for</span> (i = <span class="pl-c1">0</span>; i &lt; nitems; i += nbatch) {
  <span class="pl-k">const</span> <span class="pl-k">int</span> ibatch = <span class="pl-k">sizeof</span>(<span class="pl-k">double</span>) * <span class="pl-c1">min</span>(nbatch, nitems - i), j = i / nbatch;
  <span class="pl-c1">libxstream_memcpy_h2d</span>(ihst + i, idev, ibatch, stream[j%<span class="pl-c1">2</span>]);
  <span class="pl-c">/* TODO: invoke user function (see Function Interface) */</span>
  <span class="pl-c1">libxstream_memcpy_d2h</span>(odev, ohst + i, ibatch, stream[j%<span class="pl-c1">2</span>]);
}</pre></div>

<p>It is possible to query properties of the allocated buffers using the base address as returned by the above allocation function:</p>

<div class="highlight highlight-source-c"><pre><span class="pl-c1">size_t</span> size = <span class="pl-c1">0</span>;  <span class="pl-c">/*will be nitems x sizeof(double)*/</span>
<span class="pl-k">int</span> device = -<span class="pl-c1">1</span>;  <span class="pl-c">/*will be 'dev' because 'idev' is allocated there*/</span>
<span class="pl-k">void</span>* mapped = <span class="pl-c1">0</span>; <span class="pl-c">/*will be an address only valid on device-side*/</span>
<span class="pl-en">libxstream_mem_info</span>(idev, &amp;mapped, &amp;size, &amp;device);
<span class="pl-c">/* deallocating the above memory buffers... */</span>
<span class="pl-en">libxstream_mem_deallocate</span>(hst, ihst);
<span class="pl-en">libxstream_mem_deallocate</span>(hst, ohst);
<span class="pl-en">libxstream_mem_deallocate</span>(dev, idev);
<span class="pl-en">libxstream_mem_deallocate</span>(dev, odev);</pre></div>

<h3>
<a id="stream-interface" class="anchor" href="#stream-interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stream Interface</h3>

<p>The stream interface is used to expose the available parallelism. A stream preserves the predecessor/successor relationship while participating in a pipeline (parallel pattern) in case of multiple streams. Synchronization points can be introduced using the stream interface as well as the <a href="#event-interface">Event Interface</a>.</p>

<div class="highlight highlight-source-c"><pre>libxstream_stream* stream[<span class="pl-c1">2</span>];
<span class="pl-en">libxstream_stream_create</span>(stream + <span class="pl-c1">0</span>, d, <span class="pl-c1">0</span><span class="pl-c">/*priority*/</span>, <span class="pl-s"><span class="pl-pds">"</span>s1<span class="pl-pds">"</span></span>);
<span class="pl-en">libxstream_stream_create</span>(stream + <span class="pl-c1">1</span>, d, <span class="pl-c1">0</span><span class="pl-c">/*priority*/</span>, <span class="pl-s"><span class="pl-pds">"</span>s2<span class="pl-pds">"</span></span>);
<span class="pl-c">/* TODO: do something with the streams */</span>
<span class="pl-en">libxstream_stream_wait</span>(<span class="pl-c1">NULL</span>); <span class="pl-c">/*wait for all streams*/</span>
<span class="pl-en">libxstream_stream_destroy</span>(stream[<span class="pl-c1">0</span>]);
<span class="pl-en">libxstream_stream_destroy</span>(stream[<span class="pl-c1">1</span>]);</pre></div>

<h3>
<a id="event-interface" class="anchor" href="#event-interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Event Interface</h3>

<p>The event interface provides a more sophisticated mechanism allowing to wait for a specific work item to complete without the need to also wait for the completion of work queued after the item in question.</p>

<div class="highlight highlight-source-c"><pre>libxstream_event* event[<span class="pl-c1">2</span><span class="pl-c">/*N*/</span>];
<span class="pl-en">libxstream_event_create</span>(event + <span class="pl-c1">0</span>);
<span class="pl-en">libxstream_event_create</span>(event + <span class="pl-c1">1</span>);

<span class="pl-k">for</span> (i = <span class="pl-c1">0</span>; i &lt; nitems; i += nbatch) {
  <span class="pl-k">const</span> <span class="pl-c1">size_t</span> n = i / nbatch, j = n % N, k = (j + <span class="pl-c1">1</span>) % N;
  <span class="pl-c">/* TODO: copy-in, user function, copy-out */</span>
  <span class="pl-c1">libxstream_event_record</span>(event + j, stream + j);

  <span class="pl-c">/* synchronize work N iterations in the past */</span>
  <span class="pl-c1">libxstream_event_wait</span>(event[k]);
}

<span class="pl-en">libxstream_event_destroy</span>(event[<span class="pl-c1">0</span>]);
<span class="pl-en">libxstream_event_destroy</span>(event[<span class="pl-c1">1</span>]);</pre></div>

<h3>
<a id="function-interface" class="anchor" href="#function-interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Function Interface</h3>

<p>The function interface is used to call a user function and to describe its list of arguments (signature). The function's signature consists of inputs, outputs, or in-out arguments. An own function can be enqueued for execution within a stream by taking the address of the function. In order to avoid repeatedly allocating (and deallocating) a signature, a thread-local signature with the maximum number of arguments supported can be constructed i.e., the thread-local signature is cleared to allow starting over with an arity of zero.</p>

<div class="highlight highlight-source-c"><pre><span class="pl-c1">size_t</span> nargs = <span class="pl-c1">5</span>, arity = <span class="pl-c1">0</span>;
libxstream_argument* args = <span class="pl-c1">0</span>;
<span class="pl-en">libxstream_fn_signature</span>(&amp;args); <span class="pl-c">/*receive thread-local function signature*/</span>
<span class="pl-en">libxstream_fn_nargs</span> (args, &amp;nargs); <span class="pl-c">/*nargs==LIBXSTREAM_MAX_NARGS*/</span>
<span class="pl-en">libxstream_get_arity</span>(args, &amp;arity); <span class="pl-c">/*arity==0 (no arguments constructed yet)*/</span>
<span class="pl-en">libxstream_fn_call</span>((libxstream_function)f, args, stream, LIBXSTREAM_CALL_DEFAULT);
<span class="pl-en">libxstream_fn_destroy_signature</span>(args); <span class="pl-c">/*(can be used for many function calls)*/</span></pre></div>

<p><strong>void fc(const double* scale, const float* in, float* out, const size_t* n, size_t* nzeros)</strong><br>
For the C language, a first observation is that all arguments of the function's signature are passed "by pointer"; even a value that needs to be returned (which also allows multiple results to be delivered). Please note that non-elemental ("array") arguments are handled "by pointer" rather than by pointer-to-pointer. The mechanism to pass an argument is called "by-pointer" (or by-address) to distinct from the C++ reference type mechanism. Although all arguments are received by pointer, any elemental ("scalar") input is present by value (which is important for the argument's life-time). In contrast, an elemental output is only present by-address, and therefore care must be taken on the call-side to ensure the destination is still valid when the function is executed. The latter is because the execution is asynchronous by default.</p>

<p><strong>void fpp(const double&amp; scale, const float* in, float* out, const size_t&amp; n, size_t&amp; nzeros)</strong><br>
For the C++ language, the reference mechanism can be used to conveniently receive an elemental argument "by-value" including elemental output arguments as "non-const reference" ("return value").</p>

<div class="highlight highlight-source-c++"><pre><span class="pl-k">const</span> libxstream_type sizetype = libxstream_map_to&lt;<span class="pl-c1">size_t</span>&gt;::type();
<span class="pl-en">libxstream_fn_input</span> (args, <span class="pl-c1">0</span>, &amp;scale, libxstream_map_to_type(scale), 0, NULL);
<span class="pl-en">libxstream_fn_input</span> (args, <span class="pl-c1">1</span>, in,  LIBXSTREAM_TYPE_F32, <span class="pl-c1">1</span>, &amp;n);
<span class="pl-en">libxstream_fn_output</span>(args, <span class="pl-c1">2</span>, out, LIBXSTREAM_TYPE_F32, <span class="pl-c1">1</span>, &amp;n);
<span class="pl-en">libxstream_fn_input</span> (args, <span class="pl-c1">3</span>, &amp;n, sizetype, <span class="pl-c1">0</span>, <span class="pl-c1">NULL</span>);
<span class="pl-en">libxstream_fn_output</span>(args, <span class="pl-c1">4</span>, &amp;nzeros, sizetype, <span class="pl-c1">0</span>, <span class="pl-c1">NULL</span>);</pre></div>

<p>Beside of showing some C++ syntax in the above code snippet, the resulting signature is perfectly valid for both the "fc" and the "fpp" function. Mapping type definitions in C (and FORTRAN) similar to the above C++ code, one can rely on libxstream_get_autotype's "start" argument pointing into a "type category" (order in which types are enumerated). For example in the following code, the type "size_t" is considered to be at least an unsigned integer type but may be deduced to LIBXSTREAM_TYPE_U64 according to the result of sizeof(size_t).</p>

<div class="highlight highlight-source-c"><pre>libxstream_type sizetype = LIBXSTREAM_TYPE_U32;
<span class="pl-en">libxstream_get_autotype</span>(<span class="pl-k">sizeof</span>(<span class="pl-c1">size_t</span>), sizetype, &amp;sizetype);</pre></div>

<p><strong>Weak type information</strong><br>
To construct a signature with only weak type information, one may (1) not distinct between in-out and output arguments; even non-elemental inputs can be treated as an in-out argument, and (2) use LIBXSTREAM_TYPE_VOID as an elemental type or any other type with a type-size of one (BYTE, I8, U8, CHAR). Weak-typed arguments imply that extents are counted in Byte rather than in number of elements. Moreover, weak-typed scalar arguments need to supply a "shape" indicating the actual size of the element in Byte.</p>

<div class="highlight highlight-source-c"><pre><span class="pl-k">const</span> <span class="pl-c1">size_t</span> typesize = <span class="pl-k">sizeof</span>(<span class="pl-k">float</span>);
<span class="pl-c">/* argument type in function signature: const float* or const float&amp; */</span>
<span class="pl-en">libxstream_fn_input</span>(args, <span class="pl-c1">0</span>,  &amp;f1, LIBXSTREAM_TYPE_VOID, <span class="pl-c1">0</span>, &amp;typesize);
<span class="pl-c">/* argument type in function signature: unsigned char* */</span>
<span class="pl-en">libxstream_fn_inout</span>(args, <span class="pl-c1">1</span>, data, LIBXSTREAM_TYPE_BYTE, <span class="pl-c1">1</span>, &amp;numbytes);</pre></div>

<h3>
<a id="query-interface" class="anchor" href="#query-interface" aria-hidden="true"><span class="octicon octicon-link"></span></a>Query Interface</h3>

<p>This "device-side API" allows to query information about function arguments when inside of a user function (which is called by the library). This can be used to introspect the function's arguments in terms of type, dimensionality, shape, and other properties. In order to query a property, the position of the argument within the signature needs to be known. However, the position within the signature can be also queried (when inside of a library-initiated call context) by using the actual function argument (given by address). To refer a function's signature when inside of a function, a NULL-pointer is passed to designate the function signature of the current call context.</p>

<p><strong>Revised function "fc" querying argument properties</strong><br>
As one can see, the signature of a function can often be trimmed to omit arguments which certainly describe the shape of an argument (below function signature omits the "n" argument shown in one of the previous examples).</p>

<div class="highlight highlight-source-c"><pre>LIBXSTREAM_RETARGETABLE <span class="pl-k">void</span> <span class="pl-en">f</span>(<span class="pl-k">const</span> <span class="pl-k">double</span>* scale, <span class="pl-k">const</span> <span class="pl-k">float</span>* in, <span class="pl-k">float</span>* out, <span class="pl-c1">size_t</span>* nzeros)
{
  libxstream_type type = LIBXSTREAM_TYPE_VOID;
  <span class="pl-c1">size_t</span> in_position = <span class="pl-c1">0</span>, n = <span class="pl-c1">0</span>;
  <span class="pl-k">const</span> <span class="pl-k">char</span>* name = <span class="pl-c1">0</span>;

  <span class="pl-c1">libxstream_get_argument</span>(in, &amp;in_position); <span class="pl-c">/*in_position == 1*/</span>
  <span class="pl-c1">libxstream_get_shape</span>(<span class="pl-c1">NULL</span><span class="pl-c">/*this call context*/</span>, in_position, &amp;n);
  <span class="pl-c1">libxstream_get_type</span> (<span class="pl-c1">NULL</span><span class="pl-c">/*this call context*/</span>, <span class="pl-c1">2</span><span class="pl-c">/*out*/</span>, &amp;type);
  <span class="pl-c1">libxstream_get_typename</span>(type, &amp;name);
  <span class="pl-c1">printf</span>(<span class="pl-s"><span class="pl-pds">"</span>type=<span class="pl-c1">%s</span><span class="pl-pds">"</span></span>, name); <span class="pl-c">/*f32*/</span>
}</pre></div>

<p><strong>Variadic functions</strong><br>
The query interface allows enumerating and accessing function arguments including the raw data behind the argument. This applies regardless of whether the arguments are given explicitly or when supplied via a variadic part of the function's signature (ellipsis).</p>

<div class="highlight highlight-source-c"><pre>LIBXSTREAM_RETARGETABLE <span class="pl-k">void</span> <span class="pl-en">fill</span>(<span class="pl-k">float</span>* out, ...)
{
  <span class="pl-c1">size_t</span> n = <span class="pl-c1">0</span>, i = <span class="pl-c1">0</span>, arity = <span class="pl-c1">0</span>;
  <span class="pl-k">float</span> fill_value = <span class="pl-c1">0</span>; <span class="pl-c">/*default*/</span>
  <span class="pl-k">const</span> <span class="pl-k">void</span>* data = <span class="pl-c1">0</span>;

  <span class="pl-c1">libxstream_get_shape</span>(<span class="pl-c1">NULL</span><span class="pl-c">/*this call context*/</span>, <span class="pl-c1">0</span><span class="pl-c">/*out*/</span>, &amp;n);
  <span class="pl-c1">libxstream_get_arity</span>(<span class="pl-c1">NULL</span><span class="pl-c">/*this call context*/</span>, &amp;arity);
  <span class="pl-k">if</span> (<span class="pl-c1">1</span> &lt; arity) { <span class="pl-c">/*non-default fill value*/</span>
    <span class="pl-c1">libxstream_get_data</span>(<span class="pl-c1">NULL</span><span class="pl-c">/*this call context*/</span>, <span class="pl-c1">1</span>, &amp;data);
    fill_value = *(<span class="pl-k">const</span> <span class="pl-k">float</span>*)data; <span class="pl-c">/*better check the type*/</span>
  }
  <span class="pl-k">for</span> (i = <span class="pl-c1">0</span>; i &lt; n; ++i) out[i] = fill_value;
}</pre></div>

<h2>
<a id="performance" class="anchor" href="#performance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Performance</h2>

<p>Prior to benchmarking more complex code, a copy-in and copy-out "microbenchmark" based on the <a href="https://github.com/hfp/libxstream/tree/master/samples/copy">copy</a> sample code is performed. The performance should be only limited by the PCIe transfer speed (generation 2) rather than any other overhead induced by the library.</p>

<p><img src="samples/copy/results/Xeon_Phi-3120/copy.png" alt='This graph shows the performance of an Intel Xeon Phi 3120 Coprocessor card performing the [copy](https://github.com/hfp/libxstream/tree/master/samples/copy) benchmark. The code has been built by running "./[make.sh](https://github.com/hfp/libxstream/blob/master/samples/copy/make.sh)", and then running "./[copy.sh](https://github.com/hfp/libxstream/blob/master/samples/copy/copy.sh) i" and "./copy.sh o" on the host system. The benchmark performs a series of copy-in and copy-out operations followed by a synchronization operation after each transfer. The synchronization for every transfer is actually superfluous, however the benchmark is also attempting to capture an eventually induced overhead. The shown bandwidth is only limited by the transfer bandwidth of the PCIe gen. 2 interface, and the result is also expected to be independent of running on a 3, 5, or 7-series card.'></p>

<blockquote>
<p>This graph shows the performance of an Intel Xeon Phi 3120 Coprocessor card performing the <a href="https://github.com/hfp/libxstream/tree/master/samples/copy">copy</a> benchmark. The code has been built by running "./<a href="https://github.com/hfp/libxstream/blob/master/samples/copy/make.sh">make.sh</a>", and then running "./<a href="https://github.com/hfp/libxstream/blob/master/samples/copy/copy.sh">copy.sh</a> i" and "./copy.sh o" on the host system. The benchmark performs a series of copy-in and copy-out operations followed by a synchronization operation after each transfer. The synchronization for every transfer is actually superfluous, however the benchmark is also attempting to capture an eventually induced overhead. The shown bandwidth is only limited by the transfer bandwidth of the PCIe gen. 2 interface, and the result is also expected to be independent of running on a 3, 5, or 7-series card.</p>
</blockquote>

<p>The <a href="https://github.com/hfp/libxstream/tree/master/samples/multi-dgemm">multi-dgemm</a> sample code is the implementation of a benchmark (beside of illustrating the use of the library). The shown performance is not meant to be "the best case". The performance is reproduced by constructing a series of matrix-matrix multiplications of varying problem sizes with no attempt to avoid the implied performance penalties (see underneath the graph for more details). A reasonable implementation producing the same output is likely able to outperform the benchmark.</p>

<p><img src="samples/multi-dgemm/results/Xeon_Phi-7120/plot.png" alt='This graph shows the performance of a single Intel Xeon Phi 7120 Coprocessor card performing the [multi-dgemm](https://github.com/hfp/libxstream/tree/master/samples/multi-dgemm) benchmark. The code has been built by running "./[make.sh](https://github.com/hfp/libxstream/blob/master/samples/multi-dgemm/make.sh)", and then running "env OFFLOAD_DEVICES=0 ./[benchmark.sh](https://github.com/hfp/libxstream/blob/master/samples/multi-dgemm/benchmark.sh)" on the host system. The script varies the number of matrix-matrix multiplications queued at once. The program is rather a stress-test than a benchmark since there is no attempt to avoid the performance penalties as mentioned below. The plot is showing a performance of more than 200 GFLOPS/s even with smaller batch sizes.'></p>

<blockquote>
<p>This graph shows the performance of a single Intel Xeon Phi 7120 Coprocessor card performing the <a href="https://github.com/hfp/libxstream/tree/master/samples/multi-dgemm">multi-dgemm</a> benchmark. The code has been built by running "./<a href="https://github.com/hfp/libxstream/blob/master/samples/multi-dgemm/make.sh">make.sh</a>", and then running "env OFFLOAD_DEVICES=0 ./<a href="https://github.com/hfp/libxstream/blob/master/samples/multi-dgemm/benchmark.sh">benchmark.sh</a>" on the host system. The script varies the number of matrix-matrix multiplications queued at once. The program is rather a stress-test than a benchmark since there is no attempt to avoid the performance penalties as mentioned below. The plot is showing a performance of more than 200 GFLOPS/s even with smaller batch sizes.</p>
</blockquote>

<p>Even the series of matrices with the largest problem size exhibits an insufficient amount of FLOPS in order to hide the cost of transferring the data. The data transfers are also including a set of indices describing the offsets of each of the matrix operands in the associated buffers. The latter implies unaligned memory accesses due to packing the matrix data without a favorable leading dimension. Transfers are performed as needed on a per-computation basis rather than aggregating a single copy-in and copy-out prior and past of the benchmark cycle. Moreover, there is no attempt to balance the mixture of different problem sizes when queuing the work into the streams.</p>

<h2>
<a id="tuning" class="anchor" href="#tuning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tuning</h2>

<h3>
<a id="hybrid-parallelism" class="anchor" href="#hybrid-parallelism" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hybrid Parallelism</h3>

<p>Additional scalability can be unlocked when running an application which is parallelized using the Message Passing Interface (MPI). In this case, the device(s) can be partitioned according to the number of ranks per host processor. To read more about this, please visit the <a href="https://github.com/hfp/mpirun#mpirun-wrapper">MPIRUN WRAPPER</a> project. To estimate the impact of this technique, one can scale the number of threads on the device until the performance saturates and then partition accordingly.</p>

<h2>
<a id="implementation" class="anchor" href="#implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation</h2>

<h3>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background</h3>

<p>The library's implementation allows enqueuing work from multiple host threads in a thread-safe manner and without oversubscribing the device. The actual implementation vehicle can be configured using a <a href="https://github.com/hfp/libxstream/blob/master/include/libxstream_config.h">configuration header</a>. Currently Intel's Language Extensions for Offload (LEO) are used to perform asynchronous execution and data transfers using signal/wait clauses. Other mechanisms can be implemented e.g., hStreams or COI (both are part of the Intel Manycore Platform Software Stack), or offload directives as specified by OpenMP.<br>
The current implementation is falling back to host execution in cases where no coprocessor is present, or when the executable was not built using the Intel Compiler. However, there is no attempt (yet) to exploit the parallelism available on the host system.</p>

<h3>
<a id="limitations" class="anchor" href="#limitations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Limitations</h3>

<p>There is a known performance limitations addressed by the <a href="#roadmap">Roadmap</a>. Namely the asynchronous offload is currently disabled (see LIBXSTREAM_ASYNC in the <a href="https://github.com/hfp/libxstream/blob/master/include/libxstream_config.h">configuration header</a>) due to an improper synchronization infrastructure. This issue will be addressed along with scheduling work items. The latter is also a prerequisite for an efficient hybrid execution. Hybrid execution and Transparent High Bandwidth Memory (HBM) support will both rely on an effective association between host and "device" buffers in order to omit unnecessary memory copies.</p>

<h3>
<a id="roadmap" class="anchor" href="#roadmap" aria-hidden="true"><span class="octicon octicon-link"></span></a>Roadmap</h3>

<p>Although the library is under development, the interface is stable. There is a high confidence that all features planned are mainly work "under the hood" i.e., code written now can scale forward. The following issues are being addressed in upcoming revisions:</p>

<ul>
<li>Transparent High Bandwidth Memory (HBM) support</li>
<li>Hybrid execution (host and coprocessors)</li>
<li>Native FORTRAN interface</li>
</ul>

<h2>
<a id="applications-and-references" class="anchor" href="#applications-and-references" aria-hidden="true"><span class="octicon octicon-link"></span></a>Applications and References</h2>

<p><strong>[1] <a href="http://cp2k.org/">http://cp2k.org/</a></strong>: Open Source Molecular Dynamics application. An experimental <a href="https://github.com/cp2k/cp2k/tree/intel">branch</a> at GitHub uses the library to offload work to an Intel Xeon Phi coprocessor (see <a href="https://github.com/hfp/libxstream/raw/master/documentation/cp2k.pdf">https://github.com/hfp/libxstream/raw/master/documentation/cp2k.pdf</a>).</p>

<p><strong>[2] <a href="https://github.com/01org/pyMIC">https://github.com/01org/pyMIC</a></strong>: Python module to offload computation to Intel Xeon Phi coprocessors.</p>

<p><strong>[3] <a href="http://software.intel.com/xeonphicatalog">http://software.intel.com/xeonphicatalog</a></strong>: Intel Xeon Phi Applications and Solutions Catalog.</p>

<p><strong>[4] <a href="https://software.intel.com/en-us/articles/intel-and-third-party-tools-and-libraries-available-with-support-for-intelr-xeon-phitm">http://goo.gl/qsnOOf</a></strong>: Intel 3rd Party Tools and Libraries.</p>
      </section>
      <footer>
        <p><small>Hosted on <a href="https://pages.github.com">GitHub Pages</a> using the Dinky theme</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		
  </body>
</html>
